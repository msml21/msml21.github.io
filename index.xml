<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on MSML21</title>
    <link>https://msml21.github.io/</link>
    <description>Recent content in Home on MSML21</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Feb 2018 17:01:34 +0700</lastBuildDate>
    
	<atom:link href="https://msml21.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://msml21.github.io/about/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/about/</guid>
      <description>General Chairs: Joan Bruna, Jan Hesthaven, Lenka Zdeborova</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://msml21.github.io/aboutbk/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/aboutbk/</guid>
      <description>Lorem markdownum aequalis strigis. Saetigeri iubeas, vultu huic alvum nondum de obside ut laniavit arbor palmis, cum quin. Rupes vetat videndo, armigerae crimen habet Priamum nec.
Ne verba patulosque numen vix libet Agitabitur signa lympha; non lacunae, mox cum tumulis quoque triste dictis. Ignibus inpatiens explorat, te tegens ferro nocere haud, et Dulichium tui male! Quo sed fuit flexit et hic die solido, gloria?
 Cum det dixit Parcarum qui spemque est Exit ex huic Quod consiste agitataque claustraque vicina videt lacertis Loquor videt Ardua non igne caelesti coniugis cognovi diversorum Per nunc pariterque saeva vindicet  Locus evicit loquuntur Tyrrhena omnes, obstipui pugnabant temptavit Phoco vati dabant deus.</description>
    </item>
    
    <item>
      <title>Accepted Papers</title>
      <link>https://msml21.github.io/accepted/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/accepted/</guid>
      <description>Session 1: Optimization and Algorithms Chair: Rachel Ward (UT Austin)  Hessian-Aided Random Perturbation (HARP) Using Noisy Zeroth-Order Queries, Jingyi Zhu (Alibaba Group)  Paper Highlight
 This paper proposes a novel method for stochastic blackbox optimization using zeroth-order oracles (ZO), by using the ZO queries to estimate curvature information. The paper complements a nice theoretical analysis with compelling numerical experiments. All reviewers agreed this paper brings a very interesting contribution to the growing literature of black-box optimization.</description>
    </item>
    
    <item>
      <title>Call for Papers</title>
      <link>https://msml21.github.io/cfp/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/cfp/</guid>
      <description>We invite submissions to the Mathematical and Scientific Machine Learning.
MSML2021 is the second edition of a newly established conference, with emphasis on promoting the study of mathematical theory and algorithms of machine learning, as well as applications of machine learning in scientific computing and engineering disciplines. This conference aims to bring together the communities of machine learning, applied mathematics, and computational science and engineering, to exchange ideas and progress in this fast growing field.</description>
    </item>
    
    <item>
      <title>Computational Mathematics Workshop</title>
      <link>https://msml21.github.io/workshop_math/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/workshop_math/</guid>
      <description>Computational Mathematics Organisers: Jianfeng Lu, Gitta Kutyniok, Steve Brunton, Afonso Bandeira, Ben Peherstofer, Paris Perdikaris Date: August 17th The purpose of this workshop is to show case key contributions in the applied and computational mathematics community related to deep learning, with an emphasis on mathematical and foundational questions as well as applications to fundamental science.
    ET CET GMT+8 Speaker     9:00am-9:40am 15:00-15:40 21:00-21:40 Andrew Stuart: Learning Solution Operators For PDEs    9:50am-10:30am 15:50-16:30 21:50-22:30 Sid Mishra: On Physical Informed Neural Networks (PINNs) for computing PDEs   10:50am-11:30am 16:50-17:30 22:50-23:30 Gitta Kutyniok: The Impact of Artificial Intelligence on Parametric Partial Differential Equations   11:40am-12:20pm 17:40-18:20 23:40-00:20 Michael Brenner: Machine Learning for Partial Differential Equations   12:30pm-1pm 18:30-19:00 00:30-01:00 Round Table Discussion    Abstracts Andrew Stuart: Learning Solution Operators For PDEs Neural networks have shown great success at learning function approximators between spaces X and Y, in the setting where X is a finite dimensional Euclidean space and where Y is either a finite dimensional Euclidean space (regression) or a set of finite cardinality (classification); the neural networks learn the approximator from N data pairs {xn, yn}.</description>
    </item>
    
    <item>
      <title>Computational Physics</title>
      <link>https://msml21.github.io/session8/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/session8/</guid>
      <description>Chair: Eric Vanden-Eijnden (NYU) Time: August 19th, 1:10pm-2pm ET, 19:10-20:00 CET, 01:10-02:00 GMT+8  Implicit form neural network for learning scalar hyperbolic conservation laws, Xiaoping Zhang (Wuhan University); Tao Cheng (Wuhan University); Lili Ju (University of South Carolina).  slides video paper
Paper Highlight, by Yibo Yang:
 This paper proposes an unsupervised learning method &amp;mdash;- Implicit Form Neural Networks (IFNN) using neural networks to solve partial differential equations (PDEs) whose solutions have discontinuities such as shock waves, etc.</description>
    </item>
    
    <item>
      <title>Conference Program</title>
      <link>https://msml21.github.io/accepted_old/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/accepted_old/</guid>
      <description>Session 1: Optimization and Algorithms Chair: Rachel Ward (UT Austin)   Hessian-Aided Random Perturbation (HARP) Using Noisy Zeroth-Order Queries, Jingyi Zhu (Alibaba Group)
  Average-Case Integrality Gap for Non-Negative Principal Component Analysis, Afonso S Bandeira (ETH); Dmitriy Kunisky (New York University), Alex Wein (NYU)
  A Qualitative Study of the Dynamic Behavior for Adaptive Gradient Algorithms, Chao Ma (Princeton University), Lei Wu (Princeton University), Weinan E (Princeton University)</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://msml21.github.io/contact/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Covid-19</title>
      <link>https://msml21.github.io/covid/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/covid/</guid>
      <description>While we all desire that public health conditions will be safe to allow a MSML21 physical meeting, we acknowledge the uncertainties surrounding the current Covid-19 epidemic, and therefore contemplate the possibility of holding a virtual meeting instead, in case we cannot guarantee the safety of all participants.
Please stay tuned for continuous and further updates by following us on Twitter.
Update: After careful analysis of the situation, we have decided to hold this event Virtual.</description>
    </item>
    
    <item>
      <title>High Dimensional Statistics</title>
      <link>https://msml21.github.io/session4/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/session4/</guid>
      <description>Chairs: Marylou Gabrie (NYU-Flatiron Institute) and Ilias Zadik (NYU/MIT) Time: August 16th, 1:10pm-2pm ET, 19:10-20:00 CET, 01:10-02:00 GMT+8  Sharp threshold for alignment of graph databases with Gaussian weights, Luca Ganassali (INRIA (Paris).  Paper Highlight, by Galen Reeves
 The problem of graph alignment is to find the correspondence between the vertices in two graphs based on matching values associated with the vertices. This paper studies the fundamental limits of a particular version of this problem where the weights are correlated Gaussian variables.</description>
    </item>
    
    <item>
      <title>Inverse Problems</title>
      <link>https://msml21.github.io/session5/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/session5/</guid>
      <description>Chairs: Xiuyuan Cheng (Duke) and Yimin Zhong (Duke) Time: August 19th, 10:20am-11:10am ET, 16:20-17:10 CET, 22:20-23:10 GMT+8  Spectral Geometric Matrix Completion, Amit Boyarski (Technion); Sanketh Vedula (Technion), Alex Bronstein (Technion)  Paper Highlight, by Rachel Ward
 Consider a matrix that is composed of a linear combination of the lowest harmonic vectors of some product graph. This is a structured low-rank model, but one which arises naturally in recommender systems, where similar users tend to give similar ratings, and similar items should have similar ratings.</description>
    </item>
    
    <item>
      <title>Key Dates</title>
      <link>https://msml21.github.io/dates/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/dates/</guid>
      <description>DEADLINE EXTENSION: December 11th, 2020, 11:59pm (AOE)  Submission deadline: December 4th, 2020, 11:59pm (AOE) December 11th, 2020 (AOE). First round reviews: February 1st, 2021. Revision deadline: March 5th, 2021. Final Decisions : End of March, 2021. Conference: August 16-19th, 2021.  </description>
    </item>
    
    <item>
      <title>Learning Foundations I</title>
      <link>https://msml21.github.io/session2/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/session2/</guid>
      <description>Chair: Lenaic Chizat (EPFL) Time: August 16th, 11:10am-12:00pm ET, 17:10-18:00 CET, 23:10-0:00 GMT+8  Generalization and Memorization: The Bias Potential Model, Hongkang Yang (Princeton University), Weinan E (Princeton University)  Paper Highlight, by Song Mei
 Learning probability distributions such as generative models and density estimators are among the most essential tasks in machine learning, but its mathematical foundations are not yet well-established. This paper provided a theoretical foundation for the bias potential model, which is a simple mathematical model of probability distributions.</description>
    </item>
    
    <item>
      <title>Learning Foundations II</title>
      <link>https://msml21.github.io/session3/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/session3/</guid>
      <description>Chairs: Soledad Villar (JHU) and Teresa Huang (JHU) Time: August 16th, 12:20pm-1:10pm ET, 18:20-19:10 CET, 00:20-01:10 GMT+8  Deep Generative Learning via Euler Particle Transport, Yuan Gao (Xi&amp;rsquo;an Jiaotong University); Jian Huang (University of Iowa), Yuling Jiao (School of Statistics and Mathematics of Zhongnan University of Economics and Law); Jin Liu (Duke-NUS Medical School); Xiliang Lu (Wuhan University); Zhijian Yang (Wuhan University)  Paper Highlight, by Marylou Gabrie
 This paper proposes a new method for generative modeling based on learning a composition of residual maps that move gradually a simple base distribution toward a target distribution.</description>
    </item>
    
    <item>
      <title>Local Logistics</title>
      <link>https://msml21.github.io/local/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/local/</guid>
      <description>Stay tuned for local arrangements!</description>
    </item>
    
    <item>
      <title>MSML Board</title>
      <link>https://msml21.github.io/board/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/board/</guid>
      <description>Roberto Car (Chemistry, Princeton University)
  Weinan E (Mathematics, Princeton University)
  Anna Gilbert (Mathematics, Yale University)
  Jan Hesthaven (Mathematics, EPFL)
  George Karniadakis (Applied Mathematics, Brown University)
  Stephane Mallat (Mathematics, College de France, Flatiron Institute and Ecole Normale Superieure)
  Nathan Kutz (Applied Mathematics, University of Washington)
  Nicola Marzari (Materials, EPFL)
  Stanley Osher (Mathematics, UCLA)</description>
    </item>
    
    <item>
      <title>Optimization and Algorithms</title>
      <link>https://msml21.github.io/session1/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/session1/</guid>
      <description>Chair: Rachel Ward (UT Austin) Time: August 16th, 16:20-17:10 CET, 10:20am-11:10am ET, 22:20-23:10 GMT+8  Hessian-Aided Random Perturbation (HARP) Using Noisy Zeroth-Order Queries, Jingyi Zhu (Alibaba Group)  Paper Highlight
 This paper proposes a novel method for stochastic blackbox optimization using zeroth-order oracles (ZO), by using the ZO queries to estimate curvature information. The paper complements a nice theoretical analysis with compelling numerical experiments. All reviewers agreed this paper brings a very interesting contribution to the growing literature of black-box optimization.</description>
    </item>
    
    <item>
      <title>PDEs and ODEs</title>
      <link>https://msml21.github.io/session7/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/session7/</guid>
      <description>Chairs: Ben Peherstorfer (NYU) and Nick Boffi (NYU) Time: Aug 19th, 12:20pm-1:10pm ET, 19:10-20:00 CET, 01:10-02:00 GMT+8  Some observations on partial differential equations in Barron and multi-layer spaces, Weinan E (Princeton University); Stephan Wojtowytsch (Princeton University)  Paper Highlight, by Juncai He
 Barron and tree-like spaces are considered as appropriate function spaces to study the mathematical aspects of neural networks with one or multi hidden layers. This paper presents some observations about the Barron or tree-like regularities of solutions of three prototypical PDEs (screened Poisson, heat, and viscous HJB).</description>
    </item>
    
    <item>
      <title>Plenary Speakers</title>
      <link>https://msml21.github.io/keynote/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/keynote/</guid>
      <description>Marc Mezard Professor, Director of Ecole Normale Superieure, Paris, France. Title: Statistical physics of machine learning: successes, limitations, and perspectives
Abstract: In the last fifty years, statistical physics has elaborated a large corpus of concepts and methods to study probabilistic models in large dimensions. The connections to constraint satisfaction problems have also led to interesting algorithmic developments. This corpus provides a useful approach for theoretical studies of machine learning, complementary to traditional approaches in learning theory.</description>
    </item>
    
    <item>
      <title>Previous Years</title>
      <link>https://msml21.github.io/previous/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/previous/</guid>
      <description> MSML20, Virtual Conference.  Chairs: Jianfeng Lu (Duke), Rachel Ward (UT Austin).    </description>
    </item>
    
    <item>
      <title>Program Committee</title>
      <link>https://msml21.github.io/pc/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/pc/</guid>
      <description>General Chairs  Joan Bruna (New York University) Jan Hesthaven (EPFL) Lenka Zdeborova (EPFL)  Program Chairs  Afonso Bandeira (ETH) Jean Barbier (International Centre for Theoretical Physics) Quentin Berthet (Google) Steven L. Brunton (University of Washington) Chiara Cammarota (Sapienza, University of Rome) Michele Ceriotti (EPFL) Xiuyuan Cheng (Duke University) Lenaic Chizat (CNRS) Kyle Cranmer (NYU) Gábor Csányi (University of Cambridge) Bin Dong (Peking University) Boris Hanin (Princeton University) Shirley Ho (Flatiron Institute) Arnulf Jentzen (University of Munster) Gitta Kutyniok (LMU Munich) Qianxiao Li (NUS) Jianfeng Lu (Duke University) Pankaj Mehta (Boston University) Frank Noe (FU Berlin) Benjamin Peherstofer (NYU) Paris Perdikaris (University of Pennsylvania) Lars Ruthotto (Emory University) Themis Sapsis (MIT) Eric Vanden-Eijnden (NYU) Soledad Villar (Johns Hopkins University) Lei Wang (IOP) Rachel Ward (UT Austin)  Local Committee  Emmanuel Abbé Daniel Kressner Anne-Clemence Corminboeuf Victor Panaretos  </description>
    </item>
    
    <item>
      <title>Reinforcement Learning and Control</title>
      <link>https://msml21.github.io/session6/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/session6/</guid>
      <description>Chairs: Steven Brunton (UW) and Urban Fasel (UW) Time: August 19th, 11:10am-12:00pm ET, 17:10-18:00 CET, 23:10-00:00 GMT+8  Borrowing From the Future: Addressing Double Sampling in Model-free Control, Yuhua Zhu (Stanford University), Zachary Izzo (Stanford); Lexing Ying (Stanford University)  Paper Highlight, by Antonio Celani
 Bellman residual minimization with stochastic gradient descent (SGD) is a stable temporal-difference method whose usefulness is limited by the need of two independent samples for the state that will be visited next, rather than just one sample.</description>
    </item>
    
    <item>
      <title>Schedule</title>
      <link>https://msml21.github.io/schedule/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/schedule/</guid>
      <description>Join our Slack Workspace here to follow all updates and paper discussions. Zoom link for the conference is here.     ET CET GMT+8 Aug 16th Aug 17th Aug 18th Aug 19th     9:00am-9:10am 15:00-15:10 21:00-21:10 Opening Remarks Computational Mathematics Workshop Computational Physics Workshop MSML&#39;22 Welcome!    9:10am-10:00am 15:10-16:00 21:10-22:00 Marc Mezard Plenary Qianxiao Li Plenary   10:00am-10:20am 16:00-16:20 22:00-22:20 Break  Break    10:20am-11:10am 16:20-17:10 22:20-23:10 Session 1: Optimization and Algorithms Session 5: Inverse Problems   11:10am-12:00pm 17:10-18:00 23:10-00:00 Session 2: Learning Foundations I Session 6: Reinforcement Learning and Control   12:00pm-12:20pm 18:00-18:20 00:00-00:20 Break  Break    12:20pm-1:10pm 18:20-19:10 00:20-01:10 Session 3: Learning Foundations II Session 7: PDEs and ODEs   1:10pm-2:00pm 19:10-20:00 01:10-02:00 Session 4: High-Dimensional Statistics Session 8: Computational Physics    </description>
    </item>
    
    <item>
      <title>Workshops</title>
      <link>https://msml21.github.io/workshop_phys/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/workshop_phys/</guid>
      <description>Computational Mathematics Organisers: Jianfeng Lu, Gitta Kutyniok, Steve Brunton, Afonso Bandeira, Ben Peherstofer, Paris Perdikaris Date: August 17th The purpose of this workshop is to show case key contributions in the applied and computational mathematics community related to deep learning, with an emphasis on mathematical and foundational questions as well as applications to fundamental science.
Current Schedule, in UTC time:
 13:00 - 13:40 Andrew Stuart 13:50 - 14:30 Sid Mishra 14:50 - 15:30 Gitta Kutyniok 15:40 - 16:20 Michael Brenner 16:30 - 17:00 Round table discussion  Computational Physics Organisers Gabor Csanyi, Kyle Cranmer, Shirley Ho, Michelle Ceriotti Date: August 18th This workshop aims to explore current frontiers and challenges of Machine Learning for the physical sciences, covering a wide range of disciplines</description>
    </item>
    
    <item>
      <title>Workshops</title>
      <link>https://msml21.github.io/workshops/</link>
      <pubDate>Thu, 22 Feb 2018 17:01:34 +0700</pubDate>
      
      <guid>https://msml21.github.io/workshops/</guid>
      <description>Computational Mathematics Organisers: Jianfeng Lu, Gitta Kutyniok, Steve Brunton, Afonso Bandeira, Ben Peherstofer, Paris Perdikaris Date: August 17th The purpose of this workshop is to show case key contributions in the applied and computational mathematics community related to deep learning, with an emphasis on mathematical and foundational questions as well as applications to fundamental science.
Computational Physics Organisers Gabor Csanyi, Kyle Cranmer, Shirley Ho, Michelle Ceriotti Date: August 18th This workshop aims to explore current frontiers and challenges of Machine Learning for the physical sciences, covering a wide range of disciplines</description>
    </item>
    
  </channel>
</rss>